id: kafka_azure_log_processing
namespace: demo
description: Consume Kafka logs and process with Azure Cloud
tasks:

  - id: consume
    type: io.kestra.plugin.kafka.Consume
    topic: topic_test
    properties:
      bootstrap.servers: 'kafka-docker-kafka-1:9093'
      auto.offset.reset: earliest
    pollDuration: PT20S
    maxRecords: 50
    keyDeserializer: STRING
    valueDeserializer: JSON

  - id: write_json
    type: io.kestra.plugin.serdes.json.JsonWriter
    newLine: true
    from: "{{ outputs.consume.uri }}"

  - id: upload
    type: io.kestra.plugin.azure.storage.blob.Upload
    endpoint: "https://kestrademo.blob.core.windows.net"
    sasToken: "<token>"
    container: demo
    from: "{{ outputs.write_json.uri }}"
    name: data.json

  - id: batch
    type: io.kestra.plugin.azure.batch.job.Create
    endpoint: https://kestrademo.batch.azure.com
    account: kestrademo
    accessKey: <access-key>
    poolId: <pool-id>
    job:
      id: process_log
    tasks:
    - id: process
      commands:
      - 'python process_logs.py'
      containerSettings:
        imageName: custom_python
